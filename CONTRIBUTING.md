# Contributing to awesome-aisecurity

Thanks for your interest in contributing to **awesome-aisecurity**! üéâ  

This project aims to be a **curated list** of high-quality resources about **AI system security**:
threat modeling, adversarial ML, LLM & GenAI security, MLSecOps, privacy, governance, and more.

We welcome pull requests, issues, and suggestions.

---

## 1. What kind of contributions are welcome?

We are looking for resources that are **directly related to the security of AI systems**, including but not limited to:

- Threat modeling, frameworks, and standards for AI/ML/LLM systems.
- Attacks against models, data, and pipelines:
  - Adversarial examples, data poisoning, backdoors.
  - Model stealing / model extraction.
  - Privacy attacks (membership inference, model inversion, etc.).
  - LLM jailbreaks, prompt injection, data exfiltration, unsafe tool use.
- Defenses, evaluation frameworks, benchmarks, and datasets.
- Open-source tools and libraries that help:
  - Test, attack, or defend AI systems.
  - Monitor and harden AI pipelines, deployments, and infrastructure.
- MLSecOps / MLOps / supply chain security resources.
- Good long-form explainers, tutorials, and courses that help practitioners understand AI security.

We prefer:

- Publicly accessible resources (no private links, no obvious ‚Äúdead‚Äù links).
- Well-maintained or widely used tools.
- Papers with clear contributions or impact in the community.

---

## 2. What is *out of scope*?

To keep the list focused, we generally **do not** include:

- Generic security resources that do not specifically address AI/ML/LLM.
- ‚ÄúAI for security‚Äù (for example: using ML for intrusion detection, malware classification, etc.),
  except when they explicitly discuss **adversarial ML / robustness / security issues of the AI model itself**.
- Marketing pages with almost no technical or conceptual depth.
- Paywalled content that cannot be accessed at all without a subscription.

If in doubt, feel free to open an issue and ask.

---

## 3. Formatting rules

Please follow these **simple formatting rules** so the list stays clean and readable.

### 3.1 General rules

1. Use unordered lists with `-` (hyphen) for all items.
2. Keep **one item per line**.
3. Prefer a **single, concise sentence** that explains:
   - What the resource is, and  
   - Why it is useful in the context of AI security.
4. Place the item under the **most appropriate section**.
5. When reasonable, keep items in **alphabetical order** within a section.

### 3.2 Example formats

**Tools / libraries**

```md
- [Project Name](https://example.com) ‚Äì One-line description of what it does and why it‚Äôs useful.
