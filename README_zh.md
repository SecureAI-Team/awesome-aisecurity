# Awesome AI Security

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

一个专注于 **“AI 系统安全（Security of AI Systems）”** 的精选资源列表，内容包括开源库、工具、学术论文、标准与框架、数据集以及实战案例等。

> 关注点：**如何保护 AI 系统本身的安全与可信**（模型 / 数据 / 流水线 / 基础设施 / 治理），而不是 “用 AI 做网络安全”。

[English README](./README.md)

---

## 目录

- [动机与范围](#动机与范围)
- [基础与学习资源](#基础与学习资源)
- [威胁建模与框架](#威胁建模与框架)
- [对抗样本与传统 Adversarial ML](#对抗样本与传统-adversarial-ml)
- [LLM 与生成式 AI 安全](#llm-与生成式-ai-安全)
- [隐私、安全性与治理](#隐私安全性与治理)
- [供应链与 MLOps 安全](#供应链与-mlops-安全)
- [基础设施与运行时安全](#基础设施与运行时安全)
- [数据集与评测基准](#数据集与评测基准)
- [行业 / 场景化 AI 安全](#行业--场景化-ai-安全)
- [相关 Awesome 列表与外部资源](#相关-awesome-列表与外部资源)
- [贡献指南](#贡献指南)
- [许可证](#许可证)

---

## 动机与范围

从传统机器学习到大模型 / 多模态模型，AI 系统在 **数据、模型、流水线、基础设施与治理** 各个环节都引入了新的攻击面。

本仓库的目标是：

- 做一张 **AI 安全领域的导航图**；
- 帮助研究者与工程师快速找到 **可靠的工具、论文与框架**；
- 尽量打通 **学术研究** 与 **工程实践 / 工业落地** 之间的鸿沟。

**包含的内容（In scope）**

- 面向 **AI 系统本身** 的安全、鲁棒性与可信：
  - 对抗样本、模型窃取、数据投毒、后门等攻击与防御；
  - LLM / GenAI 安全（Prompt Injection、Jailbreak、数据外泄等）；
  - 隐私攻击与防御（差分隐私、联邦学习安全等）；
  - 模型 / 数据 / 依赖等 **供应链安全** 与 MLOps 安全；
  - 模型服务与推理基础设施安全；
  - AI 风险管理、治理与合规相关资源。

**不直接覆盖（Out of scope）**

- 与 AI 无关的通用网络安全内容；
- “AI for Security”（如：用 ML 做入侵检测）——这类内容会通过链接跳转到其它列表，而不是在此重复收录。

_最近一次更新时间（手动维护）：2025-11-26_

---

## 基础与学习资源

> 入门与系统学习 AI 安全的书籍、综述论文、课程、博客等。

- **书籍 / 综述**
  - TODO：`- **书名 / 综述题目**（年份）- 一句话描述贡献与侧重点。[链接](https://example.com)`
- **教程 / 课程**
  - TODO：`- [课程 / 教程名称](https://example.com) - 面向对象与主要内容。`
- **博客 / 周报 / Newsletter**
  - TODO：`- [博客 / Newsletter 名称](https://example.com) - 更新频率与特色。`

---

## 威胁建模与框架

> AI 安全相关的威胁建模方法、标准与最佳实践。

- **标准与指南**
  - TODO：`- [AI 风险管理 / 安全标准名称](https://example.com) - 适用场景与覆盖范围。`
- **威胁模型与分类体系**
  - TODO：`- [威胁模型 / 分类体系名称](https://example.com) - 针对的数据 / 训练 / 推理 / 供应链等阶段。`
- **检查清单与最佳实践**
  - TODO：`- [Checklist / 指南名称](https://example.com) - 适用生命周期阶段（如设计 / 开发 / 部署）。`

---

## 对抗样本与传统 Adversarial ML

> 对抗机器学习相关攻击、防御以及工具库。

### 攻击方法

- 逃逸攻击（Evasion / Adversarial Examples）
- 数据投毒与后门攻击
- 模型窃取 / 模型提取
- 成员推断 / 属性推断

示例格式：

- TODO：`- **论文 / 工具名称**（会议/年份）- 攻击类型 + 核心思想。[Paper](https://example.com) · [Code](https://example.com)`

### 防御与鲁棒训练

- 鲁棒优化与可证明鲁棒性方法
- 对抗样本检测 / 监控
- 蒸馏等其他防御手段

示例格式：

- TODO：`- **防御方法名称**（会议/年份）- 防御的威胁类型与适用场景。[Paper](https://example.com) · [Code](https://example.com)`

### 工具与库

- TODO：`- [库 / 工具名称](https://example.com) - 支持的框架（PyTorch / TensorFlow 等）与主要功能。`

---

## LLM 与生成式 AI 安全

> 面向大语言模型、多模态模型以及智能体（Agent）的安全问题与防护。

### 攻击

- Prompt Injection / Prompt 漏洞利用
- Jailbreak 与策略绕过
- 数据外泄与隐私信息推断
- 通过工具调用 / Agent 工作流的攻击

示例格式：

- TODO：`- **论文 / 资源名称**（年份）- 覆盖的威胁类型与核心结论。[Paper](https://example.com)`

### 防御与 Guardrails

- 安全策略与内容过滤
- Guardrail 框架、安全网关（Proxy / Gateway）等
- Red Teaming 方法论与评测框架
- LLM 安全 / 安全性评测基准

示例格式：

- TODO：`- [框架 / 工具名称](https://example.com) - 集成方式（SDK / Proxy / SaaS 等）与解决的问题。`

### 工具与平台

- TODO：`- [工具 / 平台名称](https://example.com) - 部署方式（托管 / 自建）及关注的安全场景。`

---

## 隐私、安全性与治理

> 隐私保护、AI 安全性与治理 / 合规方面的资源。

### 隐私攻击与防御

- 成员推断 / 属性推断攻击
- 差分隐私训练与推理
- 联邦学习安全（恶意客户端、模型更新篡改等）

示例格式：

- TODO：`- **论文名称**（会议/年份）- 所在场景（集中式 / 联邦）及攻击 / 防御类型。[Paper](https://example.com)`

### 安全性与对齐

- 安全性红队与评估
- 部署阶段的安全策略与流程
- 人在回路（Human-in-the-loop）机制

### 治理、合规与政策

- AI 风险管理框架与合规参考
- 监管指引与行业规范
- 模型卡 / 系统卡 / 风险说明文档等实践

---

## 供应链与 MLOps 安全

> 覆盖数据、模型、依赖、流水线的端到端 AI 供应链安全。

### 模型与数据供应链

- 模型仓库 / Model Hub 的安全（签名、验证、来源追踪）
- 数据集来源与完整性保护
- 依赖包、第三方组件的 SBOM / AI-BOM / 模型卡

### MLOps 与 CI/CD 安全

- 训练 / 部署流水线安全
- 密钥管理与身份与访问控制（IAM）
- 安全的模型注册表与灰度发布策略

示例格式：

- TODO：`- [工具 / 框架名称](https://example.com) - 在 MLOps 生命周期中所处位置与作用。`

---

## 基础设施与运行时安全

> 围绕模型服务与推理环境的基础设施安全。

- 机密计算与硬件隔离（TEE / enclave 等）
- 容器 / K8s 环境中的模型服务安全
- 网络安全、API 网关与速率限制
- AI 工作负载的日志、监控与审计

示例格式：

- TODO：`- [解决方案 / 项目名称](https://example.com) - 支持的云平台 / 基础设施与核心特性。`

---

## 数据集与评测基准

> 用于 AI 安全研究与评估的公开数据集与基准。

- 攻击基准（对抗样本、数据投毒等）
- 防御与鲁棒性评测基准
- LLM 安全 / 安全性评测数据集与基准

示例格式：

- TODO：`- [数据集 / 基准名称](https://example.com) - 覆盖任务、威胁类型与授权许可。`

---

## 行业 / 场景化 AI 安全

> 针对特定行业或场景的 AI 安全研究与实践。

- **工业与 OT / ICS**
  - TODO：`- [资源 / 案例名称](https://example.com) - 相关 AI 应用场景与主要安全问题。`
- **汽车与智能交通**
- **医疗与生命科学**
- **金融与银行**
- **其他行业场景**

---

## 相关 Awesome 列表与外部资源

> 一些高质量的相关列表和资源，避免在本仓库重复收录。

- TODO：`- [Awesome 列表名称](https://github.com/owner/repo) - 例如专注于 LLM 安全 / 隐私 / Safety 等方向。`

---

## 贡献指南

非常欢迎任何形式的贡献！

为了保持列表的 **质量与聚焦**，建议在提交前检查：

1. **相关性**：与 “AI 系统安全” 直接相关（而非纯粹的通用安全或 AI for Security）。
2. **质量优先**：宁缺毋滥，优先收录质量高、被社区认可的资源。
3. **稳定可访问**：尽量使用长期有效的公开链接。
4. **一句话说明价值**：每个条目都需要一行简洁的中文 / 英文描述，说明它为什么值得看。
5. **放在合适的分类下**：尽可能选择最贴切的分类。
6. **分类内按字母顺序（或时间、有明确规则）排序**。

**提交方式**

1. Fork 本仓库；
2. 新建一个分支；
3. 按统一格式在相应位置添加条目；
4. 提交 Pull Request，并在描述中简要说明 “增加了什么 / 为什么有价值”。

如果你发现以下问题，也欢迎直接开 Issue：

- 分类设计不合理 / 需要新增分类；
- 链接失效；
- 资源已经明显过时。

---

## 许可证

请根据你的偏好选择适合的许可证，例如：

- [CC0-1.0](https://creativecommons.org/publicdomain/zero/1.0/)：将列表尽可能开放到公有领域；或
- [MIT](https://opensource.org/licenses/MIT)：常见的宽松许可证。

> TODO：在仓库中添加 `LICENSE` 文件，并在此处替换为实际使用的许可证说明与链接。

